
> load("E:/Megha/R_workspace/PSA.RData")
> setwd(E:/Megha/R_workspace)
Error: unexpected '/' in "setwd(E:/"
> setwd("E:/Megha/R_workspace")
> sent.scores = score.sentiment(Shopping_site, pos.words,neg.words)
 Error in gsub("[[:punct:]]", "", sentence) : object 'sentence' not found 
> score.sentiment= function(sentences,pos.words,neg.words){
+   sent.scores= sapply(sentences,function(sentence,pos.words,neg.words){
+     #Removing Punctuations
+     sentences=gsub("[[:punct:]]","",sentence)
+     #Removing Control Characters
+     sentences=gsub("[[:cntrl:]]","",sentence)
+     #Removing digits
+     sentences=gsub("//d+","",sentence)
+     
+     #Error handling function when trying to convert lower case
+     tryTolower=function(x){
+       y=NA
+       try_error=tryCatch(tolower(x),error=function(e) e)
+       if(!inherits(try_error,"error")){
+          y=tolower(x)
+         }
+       
+         return(y)
+       }
+     sentence=sapply(sentence,tryTolower)
+     
+     #split sentence into words with str_split 
+     word.list = str_split(sentence, "\\s+")
+     words = unlist(word.list)
+     
+     #Compare words to the dictionaries of positive & negative terms
+     pos.matches = match(words, pos.words)
+     neg.matches = match(words, neg.words)
+     
+     # get the position of the matched term or NA
+     # we just want a TRUE/FALSE
+     pos.matches = !is.na(pos.matches)
+     neg.matches = !is.na(neg.matches)
+     
+     # final score
+     score = sum(pos.matches) - sum(neg.matches)
+     return(score)
+   }, pos.words, neg.words)
+   
+   # data frame with sent.scores for each sentence
+   sent.scores.datafrm = data.frame(text=sentences, score=sent.scores)
+   return(sent.scores.datafrm)
+ }
> sent.scores = score.sentiment(Shopping_site, pos.words,neg.words)
 Error in str_split(sentence, "\\s+") : 
  could not find function "str_split" 
> install.packages("twitterR")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘twitterR’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("plyr")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘plyr’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("ROAuth")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘ROAuth’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("stringr")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘stringr’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("ggplot2")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘ggplot2’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("RTextTools")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘RTextTools’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("e1071")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘e1071’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("tm")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘tm’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("dplyr")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘dplyr’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("caret")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘caret’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("openxlsx")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘openxlsx’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> install.packages("readr")
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/megha/OneDrive/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/src/contrib:
  cannot open URL 'https://cran.rstudio.com/src/contrib/PACKAGES'
Warning in install.packages :
  package ‘readr’ is not available (for R version 3.6.1)
Warning in install.packages :
  unable to access index for repository https://cran.rstudio.com/bin/windows/contrib/3.6:
  cannot open URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/PACKAGES'
> library(twitteR)
> library(plyr)

Attaching package: ‘plyr’

The following object is masked from ‘package:twitteR’:

    id

> library(ROAuth)
> library(stringr)
> library(ggplot2)
> library(e1071)
> library(tm)
Loading required package: NLP

Attaching package: ‘NLP’

The following object is masked from ‘package:ggplot2’:

    annotate

> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise, summarize

The following objects are masked from ‘package:twitteR’:

    id, location

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(caret)
Loading required package: lattice
> library(openxlsx)
> library(readr)
> sent.scores = score.sentiment(Shopping_site, pos.words,neg.words)
 Error in FUN(X[[i]], ...) : object 'pos.words' not found 
> remove(score.sentiment)
> remove(pos.word)
> remove(neg.word)
> pos.words=c(posText,"upgrade")
> neg.words=c(negText,"wtf","wait","waiting","epicfail","mechanical")
> View(Amazon_tweets)
> score.sentiment= function(sentences,pos.word,neg.words){
+   sent.scores= sapply(sentences,function(sentence,pos.word,neg.words){
+     #Removing Punctuations
+     sentences=gsub("[[:punct:]]","",sentence)
+     #Removing Control Characters
+     sentences=gsub("[[:cntrl:]]","",sentence)
+     #Removing digits
+     sentences=gsub("//d+","",sentence)
+     
+     #Error handling function when trying to convert lower case
+     tryTolower=function(x){
+       y=NA
+       try_error=tryCatch(tolower(x),error=function(e) e)
+       if(!inherits(try_error,"error")){
+          y=tolower(x)
+         }
+       
+         return(y)
+       }
+     sentence=sapply(sentence,tryTolower)
+     
+     #split sentence into words with str_split 
+     word.list = str_split(sentence, "\\s+")
+     words = unlist(word.list)
+     
+     #Compare words to the dictionaries of positive & negative terms
+     pos.matches = match(words, pos.words)
+     neg.matches = match(words, neg.words)
+     
+     # get the position of the matched term or NA
+     # we just want a TRUE/FALSE
+     pos.matches = !is.na(pos.matches)
+     neg.matches = !is.na(neg.matches)
+     
+     # final score
+     score = sum(pos.matches) - sum(neg.matches)
+     return(score)
+   }, pos.words, neg.words)
+   
+   # data frame with sent.scores for each sentence
+   sent.scores.datafrm = data.frame(text=sentences, score=sent.scores)
+   return(sent.scores.datafrm)
+ }
There were 50 or more warnings (use warnings() to see the first 50)
> score.sentiment= function(sentences,pos.words,neg.words){
+   sent.scores= sapply(sentences,function(sentence,pos.word,neg.words){
+     #Removing Punctuations
+     sentences=gsub("[[:punct:]]","",sentence)
+     #Removing Control Characters
+     sentences=gsub("[[:cntrl:]]","",sentence)
+     #Removing digits
+     sentences=gsub("//d+","",sentence)
+     
+     #Error handling function when trying to convert lower case
+     tryTolower=function(x){
+       y=NA
+       try_error=tryCatch(tolower(x),error=function(e) e)
+       if(!inherits(try_error,"error")){
+          y=tolower(x)
+         }
+       
+         return(y)
+       }
+     sentence=sapply(sentence,tryTolower)
+     
+     #split sentence into words with str_split 
+     word.list = str_split(sentence, "\\s+")
+     words = unlist(word.list)
+     
+     #Compare words to the dictionaries of positive & negative terms
+     pos.matches = match(words, pos.words)
+     neg.matches = match(words, neg.words)
+     
+     # get the position of the matched term or NA
+     # we just want a TRUE/FALSE
+     pos.matches = !is.na(pos.matches)
+     neg.matches = !is.na(neg.matches)
+     
+     # final score
+     score = sum(pos.matches) - sum(neg.matches)
+     return(score)
+   }, pos.words, neg.words)
+   
+   # data frame with sent.scores for each sentence
+   sent.scores.datafrm = data.frame(text=sentences, score=sent.scores)
+   return(sent.scores.datafrm)
+ }
> sent.scores = score.sentiment(Shopping_site, pos.words,neg.words)
> View(sent.scores)
> sent.scores$Shopping_site = factor(rep(c("Amazon", "Flipkart","Myntra"), noof_tweets))
> sent.scores$positive <- as.numeric(sent.scores$score >0)
> sent.scores$negative <- as.numeric(sent.scores$score <0)
> sent.scores$neutral <- as.numeric(sent.scores$score==0)
> Amazon_Shopping_Site <- subset(sent.scores, sent.scores$Shopping_Site=="Amazon")
> Amazon_Shopping_Site <- subset(sent.scores, sent.scores$Shopping_Site=="Amazon")
> View(Amazon_Shopping_Site)
> Amazon_Shopping_Site <- subset(sent.scores, sent.scores$Shopping_site=="Amazon")
> Flipkart_Shopping_Site <- subset(sent.scores,sent.scores$Shopping_site=="Flipkart")
> Myntra_Shopping_Site <- subset(sent.scores,sent.scores$Shopping_site=="Myntra")
> Amazon_Shopping_Site$polarity <- ifelse(Amazon_Shopping_Site$score >0,"positive",ifelse(Amazon_Shopping_Site$score < 0,"negative",ifelse(Amazon_Shopping_Site$score==0,"Neutral",0)))
> Flipkart_Shopping_Site$polarity <- ifelse(Flipkart_Shopping_Site$score >0,"positive",ifelse(Flipkart_Shopping_Site$score < 0,"negative",ifelse(Flipkart_Shopping_Site$score==0,"Neutral",0)))
> Myntra_Shopping_Site$polarity <- ifelse(Myntra_Shopping_Site$score >0,"positive",ifelse(Myntra_Shopping_Site$score < 0,"negative",ifelse(Myntra_Shopping_Site$score==0,"Neutral",0)))
> qplot(factor(polarity), data=Amazon_Shopping_Site, geom="bar", fill=factor(polarity))+xlab("Polarity Categories")+ylab("Frequency")+ggtitle("Customer Sentiments - Amazon Shopping Site")
> qplot(factor(score), data=Amazon_Shopping_Site, geom="bar", fill=factor(score))+xlab("Sentiment Score")+ylab("Frequency")+ggtitle("Customer Sentiment Scores - Amazon Shopping Site")
> qplot(factor(polarity), data=Flipkart_Shopping_Site, geom="bar",fill=factor(polarity))
>        +xlab("Polarity Categories")+ylab("Frequency")
Error in +xlab("Polarity Categories") : 
  invalid argument to unary operator
>        + ggtitle(" Customer Sentiments - Flipkart Shopping Site")
Error in +ggtitle(" Customer Sentiments - Flipkart Shopping Site") : 
  invalid argument to unary operator
> qplot(factor(polarity), data=Flipkart_Shopping_Site, geom="bar",fill=factor(polarity))
>        +xlab("Polarity Categories")+ylab("Frequency")
Error in +xlab("Polarity Categories") : 
  invalid argument to unary operator
>        +ggtitle(" Customer Sentiments - Flipkart Shopping Site")
Error in +ggtitle(" Customer Sentiments - Flipkart Shopping Site") : 
  invalid argument to unary operator
>        qplot(factor(polarity), data=Flipkart_Shopping_Site, geom="bar",fill=factor(polarity))+xlab("Polarity Categories")+ylab("Frequency")+ggtitle(" Customer Sentiments - Flipkart Shopping Site")
>        qplot(factor(score), data=Flipkart_Shopping_Site, geom="bar",fill=factor(score))+xlab("Sentiment Score")+ylab("Frequency")+ggtitle("Customer Sentiment Scores - Flipkart Shopping Site")
>        qplot(factor(polarity), data=Myntra_Shopping_Site, geom="bar",fill=factor(polarity))+xlab("Polarity Categories")+ylab("Frequency")+ggtitle("Customer Sentiments - Myntra Shopping Site") 
>        qplot(factor(score), data=Myntra_Shopping_Site, geom="bar",fill=factor(score))+xlab("Sentiment Score")+ylab("Frequency")+ggtitle("Customer Sentiment Scores - Myntra Shopping Site ")
> datafrm = ddply(sent.scores, c("Shopping_Site"),summarise,pos_count=sum( positive ),neg_count=sum( negative ),neu_count=sum(neutral))
Error in FUN(X[[i]], ...) : object 'Shopping_Site' not found
> datafrm = ddply(sent.scores, c("Shopping_site"),summarise,pos_count=sum( positive ),neg_count=sum( negative ),neu_count=sum(neutral))
> datafrm$total_count = datafrm$pos_count +datafrm$neg_count + datafrm$neu_count
> datafrm$pos_percent_score = round( 100*datafrm$pos_count/datafrm$total_count )
> 
> datafrm$neg_percent_score = round( 100*datafrm$neg_count/datafrm$total_count )
> 
> datafrm$neu_percent_score = round( 100*datafrm$neu_count/datafrm$total_count )
> View(datafrm)
> attach(datafrm)
The following object is masked _by_ .GlobalEnv:

    Shopping_site

> 
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$pos_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep="")
> 
> pie(pos_percent_score, labels = pie.chart.lbls, col = rainbow(length(pie.chart.lbls)), 
+       main = "Positive Comparative Analysis - Shopping Site")
> attach(datafrm)
The following object is masked _by_ .GlobalEnv:

    Shopping_site

The following objects are masked from datafrm (pos = 3):

    neg_count, neg_percent_score, neu_count, neu_percent_score, pos_count, pos_percent_score, Shopping_site, total_count

> 
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$pos_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep=" ")
> 
> pie(pos_percent_score, labels = pie.chart.lbls, col = rainbow(length(pie.chart.lbls)), 
+       main = "Positive Comparative Analysis - Shopping Site")
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$neg_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep="")
> 
> pie(neg_percent_score, labels = pie.chart.lbls, col = 
+       rainbow(length(pie.chart.lbls)), main = " Negative 
+ Comparative Analysis - Shopping Site")
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$neg_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep=" ")
> 
> pie(neg_percent_score, labels = pie.chart.lbls, col = 
+       rainbow(length(pie.chart.lbls)), main = " Negative 
+ Comparative Analysis - Shopping Site")
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$neu_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep="")
> 
> pie(neu_percent_score, labels = pie.chart.lbls, col = 
+       rainbow(length(pie.chart.lbls)), main = "Neutral Comparative 
+ Analysis - Shopping Site")       
> pie.chart.lbls <-paste(datafrm$Shopping_Site,datafrm$neu_percent_score)
> 
> pie.chart.lbls <- paste(pie.chart.lbls,"percent",sep=" ")
> 
> pie(neu_percent_score, labels = pie.chart.lbls, col = 
+       rainbow(length(pie.chart.lbls)), main = "Neutral Comparative 
+ Analysis - Shopping Site")  
> write.table(Amazon_Shopping_Site,"E:/Megha/R_workspace/Amazon_Shopping_Site.csv", append=T, row.names=F, col.names=T,sep=",",)
Warning message:
In write.table(Amazon_Shopping_Site, "E:/Megha/R_workspace/Amazon_Shopping_Site.csv",  :
  appending column names to file
> Amazon_Shopping_Site_csv <-read.csv("E:/Megha/R_workspace/Amazon_Shopping_Site.csv", header = TRUE, encoding = "UCS-2LE")
> View(Amazon_Shopping_Site)
> View(Amazon_Shopping_Site_csv)
> df<- read.csv("Amazon_Shopping_Site_classif1.csv", stringsAsFactors = FALSE)
> head(df)
                                                                                                                                           text
1   I just listed: 'Hot Wheels 2019 Team Transport Car Culsture Series '66 Super Nova and Retro Rig Black Hole Limited… https://t.co/3yiAjL4bk1
2             5x7ft Light Grey Wood Wall Photography Backdrop Gray Wooden Floor Photo Backg... https://t.co/UgNF32NneM <U+6765><U+81EA> @amazon
3  RT @meskue: If you get the @amazon gift guide, keep an eye out for some raucous raccoons!  #TrashPandas  @EskueLisa @Gamewright @RedRookGam…
4       RT @goldmedalmind: The Young Champion's Mind: How to Think, Train, and Thrive Like an Elite Athl... https://t.co/NC1764WWxL via @amazon
5 RT @judehaste_write: #humorous #escapism @judehaste_write \nDon't Shout it Out!: A Comical, Romantic Romp that leads all the way to Downi...…
6             7x5 ft Red Christmas Photography Backdrops Customized Snowflake Photo Studio ... https://t.co/O7u2omifEh <U+6765><U+81EA> @amazon
     Class  X X.1 X.2 X.3 X.4 X.5
1 positive NA  NA  NA  NA  NA    
2  Neutral NA  NA  NA  NA  NA    
3  Neutral NA  NA  NA  NA  NA    
4 positive NA  NA  NA  NA  NA    
5 positive NA  NA  NA  NA  NA    
6  Neutral NA  NA  NA  NA  NA    
> View(df)
> df<- read.csv("Amazon_Shopping_Site_classif1.csv", stringsAsFactors = FALSE)
> head(df)
                                                                                                                                           text
1   I just listed: 'Hot Wheels 2019 Team Transport Car Culsture Series '66 Super Nova and Retro Rig Black Hole Limited… https://t.co/3yiAjL4bk1
2             5x7ft Light Grey Wood Wall Photography Backdrop Gray Wooden Floor Photo Backg... https://t.co/UgNF32NneM <U+6765><U+81EA> @amazon
3  RT @meskue: If you get the @amazon gift guide, keep an eye out for some raucous raccoons!  #TrashPandas  @EskueLisa @Gamewright @RedRookGam…
4       RT @goldmedalmind: The Young Champion's Mind: How to Think, Train, and Thrive Like an Elite Athl... https://t.co/NC1764WWxL via @amazon
5 RT @judehaste_write: #humorous #escapism @judehaste_write \nDon't Shout it Out!: A Comical, Romantic Romp that leads all the way to Downi...…
6             7x5 ft Red Christmas Photography Backdrops Customized Snowflake Photo Studio ... https://t.co/O7u2omifEh <U+6765><U+81EA> @amazon
     class
1 positive
2  Neutral
3  Neutral
4 positive
5 positive
6  Neutral
> df <- df[sample(nrow(df)), ]
> 
> df <- df[sample(nrow(df)), ]
> 
> head(df)
                                                                                                                                               text
438    RT @wirecard: Financial insitutions can, and must, apply many of the same methods of @amazon to improve their own #personalization efforts.…
462                        The Complexity of the Irregular Verbal and Nominal Forms &amp; the Phonological C... https://t.co/kjQmfCNqjw via @amazon
668 Découvrez la vie du petit Zayan à l'#ecolodge #AtlasKasbah à #agadir au #Maroc &amp; celles d'enfants de du monde dans… https://t.co/HiKLb8kToL
815    RT @caroogarr26: Es lo que tiene, tener @amazon  #Prime que ya me ha llegado mi regalo de Navidad. El libro #LaVidaTeEstaEsperando de @Jiri…
323 RT @swati_a: @AmazonHelp @amazonIN @AmazonNews_IN @amazon \nI have been #cheated by your side\nReceived a #fake  gift card\nNo proper response…
111                                                                                                 @albaypel @amazon Ahahahhahaha ayarlasan olmaz!
       class
438 positive
462 negative
668  Neutral
815  Neutral
323 positive
111  Neutral
> 
> str(df)
'data.frame':	989 obs. of  2 variables:
 $ text : chr  "RT @wirecard: Financial insitutions can, and must, apply many of the same methods of @amazon to improve their o"| __truncated__ "The Complexity of the Irregular Verbal and Nominal Forms &amp; the Phonological C... https://t.co/kjQmfCNqjw via @amazon" "Découvrez la vie du petit Zayan à l'#ecolodge #AtlasKasbah à #agadir au #Maroc &amp; celles d'enfants de du mon"| __truncated__ "RT @caroogarr26: Es lo que tiene, tener @amazon  #Prime que ya me ha llegado mi regalo de Navidad. El libro #La"| __truncated__ ...
 $ class: chr  "positive" "negative" "Neutral" "Neutral" ...
> 
> df$class <- as.factor(df$class)  
> df <- df[sample(nrow(df)), ]
> df <- df[sample(nrow(df)), ]
> head(df)
                                                                                                                                                                                                              text
616                                                                 @adeyemo_ramota Don’t waste your money oooo\nBcos one person will buy it and boom!!!\nWe don get the photocopy or pdf… https://t.co/YRm2RKsTkO
584                                                                                          Just saw this on Amazon: PregEgg Personal 9-Month Countdown by PregEgg for $14.99 https://t.co/wQxHIFp75a via @amazon
497                                                                           @amazon gentilmente mi occorre assistenza tecnica per il mio account,vorrei essere contattato,grazie #assistenza #amazon @AmazonHelp
773 RT @HeathLegend: Heath Ledger’s ‘Candy’ (2006) <U+0001F1E6><U+0001F1FA> Reissued and Released on Blu-ray (A/1) from Shout Select in USA <U+0001F1FA><U+0001F1F8> and Canada <U+0001F1E8><U+0001F1E6> on 3 Dec…
450                                                                                           Funny Lazy Sloth in Astronaut Suit for Space Mission Design T-Shirt Sloth in ... https://t.co/GhTvBMeQKB via @amazon
488                                                                                           Arabic Love Poetry from the Desert: Majnun Leyla, Arabic Text, Commentary and... https://t.co/aTy5Ub9QBa via @amazon
       class
616 negative
584  Neutral
497  Neutral
773  Neutral
450 negative
488 positive
> str(df)
'data.frame':	989 obs. of  2 variables:
 $ text : chr  "@adeyemo_ramota Don’t waste your money oooo\nBcos one person will buy it and boom!!!\nWe don get the photocopy "| __truncated__ "Just saw this on Amazon: PregEgg Personal 9-Month Countdown by PregEgg for $14.99 https://t.co/wQxHIFp75a via @amazon" "@amazon gentilmente mi occorre assistenza tecnica per il mio account,vorrei essere contattato,grazie #assistenz"| __truncated__ "RT @HeathLegend: Heath Ledger’s ‘Candy’ (2006) <U+0001F1E6><U+0001F1FA> Reissued and Released on Blu-ray (A/1) "| __truncated__ ...
 $ class: Factor w/ 3 levels "negative","Neutral",..: 1 2 2 2 1 3 3 2 3 2 ...
> df$class <- as.factor(df$class)       
> corpus <- VCorpus(VectorSource(df$text))      
> corpus
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 989
> inspect(corpus[1:3])
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 3

[[1]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 140

[[2]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 117

[[3]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 132

> corpus.clean <- corpus %>% tm_map(content_transformer(tolower)) %>%
+   tm_map(removePunctuation) %>% tm_map(removeNumbers) %>%
+   tm_map(removeWords, stopwords(kind="en")) %>% tm_map(stripWhitespace)
> corpus.clean <- corpus %>% tm_map(content_transformer(tolower)) %>%tm_map(removePunctuation) %>% tm_map(removeNumbers) %>%tm_map(removeWords, stopwords(kind="en")) %>% tm_map(stripWhitespace)
> dtm <- DocumentTermMatrix(corpus.clean)
> inspect(dtm[40:50, 10:15])
<<DocumentTermMatrix (documents: 11, terms: 6)>>
Non-/sparse entries: 0/66
Sparsity           : 100%
Maximal term length: 7
Weighting          : term frequency (tf)
Sample             :
    Terms
Docs aaaaa aaj aajtak aaya ab… abalone
  40     0   0      0    0   0       0
  41     0   0      0    0   0       0
  42     0   0      0    0   0       0
  43     0   0      0    0   0       0
  44     0   0      0    0   0       0
  45     0   0      0    0   0       0
  46     0   0      0    0   0       0
  47     0   0      0    0   0       0
  48     0   0      0    0   0       0
  49     0   0      0    0   0       0
  50     0   0      0    0   0       0
> df.train <- df[1:1200,]
> df.test <- df[1201:1554,]
> dtm.train <- dtm[1:1200,]
Error in `[.simple_triplet_matrix`(dtm, 1:1200, ) : 
  subscript out of bounds
> dtm.test <- dtm[1201:1554,]
Error in `[.simple_triplet_matrix`(dtm, 1201:1554, ) : 
  subscript out of bounds
> View(df.test)
> remove(corpus)
> remove(corpus.clean)
> remove(df)
> remove(datafrm)
> remove(df.test)
> remove(df.train)
> remove(dtm)
> write.table(Amazon_Shopping_Site,"E:/Megha/R_workspace/Amazon_Shopping_Site.csv", append=T, row.names=F, col.names=T,sep=",",)
Warning message:
In write.table(Amazon_Shopping_Site, "E:/Megha/R_workspace/Amazon_Shopping_Site.csv",  :
  appending column names to file
> write.table(Amazon_Shopping_Site,"E:/Megha/R_workspace/Amazon_Shopping_Site.csv", append=T, row.names=F, col.names=T,sep=",",)
Warning message:
In write.table(Amazon_Shopping_Site, "E:/Megha/R_workspace/Amazon_Shopping_Site.csv",  :
  appending column names to file
> View(Amazon_Shopping_Site_csv)
> View(Amazon_Shopping_Site)
> Amazon_Shopping_Site_csv <-read.csv("E:/Megha/R_workspace/Amazon_Shopping_Site.csv", header = TRUE, encoding = "UCS-2LE")
> df<- read.csv("Amazon_Shopping_Site_classif1.csv", stringsAsFactors = FALSE)
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'Amazon_Shopping_Site_classif1.csv': No such file or directory
> View(Amazon_Shopping_Site_csv)
> remove(Amazon_Shopping_Site_csv)
> library(readxl)
> write.table(Amazon_Shopping_Site,"E:/Megha/R_workspace/Amazon_Shopping_Site.csv", append=T, row.names=F, col.names=T,sep=",",)
Warning message:
In write.table(Amazon_Shopping_Site, "E:/Megha/R_workspace/Amazon_Shopping_Site.csv",  :
  appending column names to file
> Amazon_Shopping_Site_csv <-read.csv("E:/Megha/R_workspace/Amazon_Shopping_Site.csv", header = TRUE, encoding = "UCS-2LE")
> View(Amazon_Shopping_Site_csv)
> df<- read.csv("Amazon_Shopping_Site_classif1.csv", stringsAsFactors = FALSE)
> head(df)
                                                                                                                                           text
1   I just listed: 'Hot Wheels 2019 Team Transport Car Culsture Series '66 Super Nova and Retro Rig Black Hole Limited… https://t.co/3yiAjL4bk1
2             5x7ft Light Grey Wood Wall Photography Backdrop Gray Wooden Floor Photo Backg... https://t.co/UgNF32NneM <U+6765><U+81EA> @amazon
3  RT @meskue: If you get the @amazon gift guide, keep an eye out for some raucous raccoons!  #TrashPandas  @EskueLisa @Gamewright @RedRookGam…
4       RT @goldmedalmind: The Young Champion's Mind: How to Think, Train, and Thrive Like an Elite Athl... https://t.co/NC1764WWxL via @amazon
5 RT @judehaste_write: #humorous #escapism @judehaste_write \nDon't Shout it Out!: A Comical, Romantic Romp that leads all the way to Downi...…
6             7x5 ft Red Christmas Photography Backdrops Customized Snowflake Photo Studio ... https://t.co/O7u2omifEh <U+6765><U+81EA> @amazon
     class X
1 positive  
2  Neutral  
3  Neutral  
4 positive  
5 positive  
6  Neutral  
> set.seed(1)
> df <- df[sample(nrow(df)), ]
> df <- df[sample(nrow(df)), ]
> head(df)
                                                                                                                                            text
924 @amazon r/concern I have a problem with Amazon app when I try to login it show u have no account when I try to crea… https://t.co/v6lfEG9Aeu
91                           Check out this Amazon deal: Roku Express HD Streaming Media Player 2019 by Roku https://t.co/TWx0O6wUkh via @amazon
233            BELIEVE! Breast Cancer Survivor PopSocket for cell phones https://t.co/NnJCqnwQHH #breastcancerawareness… https://t.co/HeyGgRBO29
181 @AnthonyMSeoane @amazon @PrimeVideo @jackryanamazon I’ve got two more left in season two, by far the most messed up… https://t.co/nGcpBjSpc8
673                                                        RT @zaidacastillo51: @Sparti941 <U+270D><U+FE0F>\n#RecomiendoLeer \\CUENTOS INÉDITOS:
211                                          the dark saga (the dark present series Book 2) by ashley willis https://t.co/JUAmldyMJO via @amazon
       class X
924 negative  
91   Neutral  
233  Neutral  
181 negative  
673           
211 negative  
> str(df)
'data.frame':	1022 obs. of  3 variables:
 $ text : chr  "@amazon r/concern I have a problem with Amazon app when I try to login it show u have no account when I try to "| __truncated__ "Check out this Amazon deal: Roku Express HD Streaming Media Player 2019 by Roku https://t.co/TWx0O6wUkh via @amazon" "BELIEVE! Breast Cancer Survivor PopSocket for cell phones https://t.co/NnJCqnwQHH #breastcancerawareness… https"| __truncated__ "@AnthonyMSeoane @amazon @PrimeVideo @jackryanamazon I’ve got two more left in season two, by far the most messe"| __truncated__ ...
 $ class: chr  "negative" "Neutral" "Neutral" "negative" ...
 $ X    : chr  "" "" "" "" ...
> df$class <- as.factor(df$class)      
> corpus <- VCorpus(VectorSource(df$text))      
> corpus
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 1022
> inspect(corpus[1:3])
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 3

[[1]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 140

[[2]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 115

[[3]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 129

> corpus.clean <- corpus %>% tm_map(content_transformer(tolower)) %>%tm_map(removePunctuation) %>% tm_map(removeNumbers) %>%tm_map(removeWords, stopwords(kind="en")) %>% tm_map(stripWhitespace)
> dtm <- DocumentTermMatrix(corpus.clean)
> inspect(dtm[40:50, 10:15])
<<DocumentTermMatrix (documents: 11, terms: 6)>>
Non-/sparse entries: 0/66
Sparsity           : 100%
Maximal term length: 6
Weighting          : term frequency (tf)
Sample             :
    Terms
Docs “work” «mon aaaaa aaj aajtak aaya
  40      0    0     0   0      0    0
  41      0    0     0   0      0    0
  42      0    0     0   0      0    0
  43      0    0     0   0      0    0
  44      0    0     0   0      0    0
  45      0    0     0   0      0    0
  46      0    0     0   0      0    0
  47      0    0     0   0      0    0
  48      0    0     0   0      0    0
  49      0    0     0   0      0    0
  50      0    0     0   0      0    0
> df.train <- df[1:1200,]
> df.train <- df[1:700,]
> df.test <- df[701:1022,]
> dtm.train <- dtm[1:700,]
> dtm.test <- dtm[701:1022,]
> corpus.clean.train <- corpus.clean[1:700]
> corpus.clean.test <- corpus.clean[701:1022]
>   dim(dtm.train)
[1]  700 4530
>   fivefreq <- findFreqTerms(dtm.train, 5)       
>   length((fivefreq))
[1] 252
>   dim(dtm.train)
[1]  700 4530
>   fivefreq <- findFreqTerms(dtm.train, 5)   
>   dtm.train.nb <- DocumentTermMatrix(corpus.clean.train, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 252
>   dtm.test.nb <- DocumentTermMatrix(corpus.clean.test, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 252
>   convert_count <- function(x) {
+     y <- ifelse(x > 0, 1,0)
+     y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
+     y
+   }
>   trainNB <- apply(dtm.train.nb, 2, convert_count)
>   testNB <- apply(dtm.test.nb, 2, convert_count)  
>   system.time( classifier <- naiveBayes(trainNB, df.train$class,laplace = 1) )
   user  system elapsed 
   0.04    0.00    0.05 
>   system.time( pred <- predict(classifier, newdata=testNB) )
   user  system elapsed 
   1.26    0.00    1.27 
>   table("Predictions"= pred, "Actual" = df.test$class )
           Actual
Predictions       0   1 negative Neutral positive
              1   0   0        0       0        0
   0          0   0   0        0       0        0
   1          0   0   0        0       0        0
   negative   0   0   0       14       5        3
   Neutral    5   1   3       25     179       33
   positive   1   0   0        2      14       36
>   conf.mat <- confusionMatrix(pred, df.test$class)
Error in `[.default`(data, , pos) : subscript out of bounds
> View(dtm.test)
> View(df)
Warning message:
In doTryCatch(return(expr), name, parentenv, handler) :
  display list redraw incomplete
>   remove(corpus)
>   remove(corpus.clean)
>   remove(df)
>   remove(datafrm)
Warning message:
In remove(datafrm) : object 'datafrm' not found
>   remove(df.test)
>   remove(df.train)
>   remove(dtm)
>   remove(classifier)
>   remove(corpus.clean.train)
>   remove(corpus.clean.test)
>   remove(dtm.test)
>   remove(dtm.test.nb)
>   remove(dtm.train)
>   remove(dtm.train.nb)
>   remove(convert_count())
Error in remove(convert_count()) : 
  ... must contain names or character strings
>   remove(convert_count)
>   remove(pred)
>   remove(fivefreq)
> write.table(Amazon_Shopping_Site,"E:/Megha/R_workspace/Amazon_Shopping_Site.csv", append=T, row.names=F, col.names=T,sep=",",)
Warning message:
In write.table(Amazon_Shopping_Site, "E:/Megha/R_workspace/Amazon_Shopping_Site.csv",  :
  appending column names to file
> Amazon_Shopping_Site_csv <-read.csv("E:/Megha/R_workspace/Amazon_Shopping_Site.csv", header = TRUE, encoding = "UCS-2LE")
> df<- read.csv("Amazon_Shopping_Site_classif1.csv", stringsAsFactors = FALSE)
> View(df)
> head(df)
                                                                                                                                           text
1   I just listed: 'Hot Wheels 2019 Team Transport Car Culsture Series '66 Super Nova and Retro Rig Black Hole Limited… https://t.co/3yiAjL4bk1
2             5x7ft Light Grey Wood Wall Photography Backdrop Gray Wooden Floor Photo Backg... https://t.co/UgNF32NneM <U+6765><U+81EA> @amazon
3  RT @meskue: If you get the @amazon gift guide, keep an eye out for some raucous raccoons!  #TrashPandas  @EskueLisa @Gamewright @RedRookGam…
4       RT @goldmedalmind: The Young Champion's Mind: How to Think, Train, and Thrive Like an Elite Athl... https://t.co/NC1764WWxL via @amazon
5 RT @judehaste_write: #humorous #escapism @judehaste_write \nDon't Shout it Out!: A Comical, Romantic Romp that leads all the way to Downi...…
6             7x5 ft Red Christmas Photography Backdrops Customized Snowflake Photo Studio ... https://t.co/O7u2omifEh <U+6765><U+81EA> @amazon
  polarity
1 positive
2  Neutral
3  Neutral
4 positive
5 positive
6  Neutral
> set.seed(1)
> df <- df[sample(nrow(df)), ]
> df <- df[sample(nrow(df)), ]
> head(df)
                                                                                                                                                                                                                                                                                                                                                                                      text
18                                                                                                                                                                                                                                            And then there was the 2017 plan to give Reservation 13 to @Amazon. @DMPEDDC told @nickburgerdc that it didn’t have… https://t.co/jyOoRO0odk
1546                                                                                                                                                                                                                                                                                               @amazon please ship whole carton of burnol to Daniel aka ga@ndu https://t.co/pCZJv39J2V
959                                                                                                                                                                                                                                            RT @SolarPrepper: An Old Man And His Axe: A Prepper fiction book of survival in an EMP grid down https://t.co/D9irbfzWg4 via @amazon #SHTF…
701                                                                                                                                                                                                      RT @AmazonEnLucha: <U+203C><U+FE0F>@Amazon desafía la decisión de la corte de Carolina del Sur de que debe hasta 12.5M $ en impuestos por las ventas\n\n<U+0001F1FA><U+0001F1F8>…
711  <U+3010><U+3068><U+3042><U+308B>if<U+3011><U+96D1><U+8AC7><U+FF1F><U+26A0><U+30AF><U+30E9><U+30ED><U+30EF><U+3067><U+306F><U+3042><U+308A><U+307E><U+305B><U+3093><U+3002><U+4F5C><U+696D>@Amazon<U+30DE><U+30C3><U+30C8><U+8A66><U+3057><U+4E2D>  ##<U+3068><U+3042><U+308B>IF  #<U+30DF><U+30E9><U+30C6><U+30A3><U+30D6> <U+3067><U+914D><U+4FE1><U+4E2D>!  https://t.co/2IFjucXzry
1882                                                                                                                                                                                                                                                     Spezielle chinesische Nahrung Lotuswurzelstärke 1 Pfund (454 Gramm) süßer Ges... https://t.co/QhdpEjhAXl <U+6765><U+81EA> @amazon
     polarity
18    Neutral
1546  Neutral
959   Neutral
701   Neutral
711   Neutral
1882  Neutral
> str(df)
'data.frame':	2045 obs. of  2 variables:
 $ text    : chr  "And then there was the 2017 plan to give Reservation 13 to @Amazon. @DMPEDDC told @nickburgerdc that it didn’t "| __truncated__ "@amazon please ship whole carton of burnol to Daniel aka ga@ndu https://t.co/pCZJv39J2V" "RT @SolarPrepper: An Old Man And His Axe: A Prepper fiction book of survival in an EMP grid down https://t.co/D"| __truncated__ "RT @AmazonEnLucha: <U+203C><U+FE0F>@Amazon desafía la decisión de la corte de Carolina del Sur de que debe hast"| __truncated__ ...
 $ polarity: chr  "Neutral" "Neutral" "Neutral" "Neutral" ...
> df$class <- as.factor(df$class)      
Error in `$<-.data.frame`(`*tmp*`, class, value = integer(0)) : 
  replacement has 0 rows, data has 2045
> corpus <- VCorpus(VectorSource(df$text))      
> corpus
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 2045
> inspect(corpus[1:3])
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 3

[[1]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 140

[[2]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 87

[[3]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 139

> corpus.clean <- corpus %>% tm_map(content_transformer(tolower)) %>%tm_map(removePunctuation) %>% tm_map(removeNumbers) %>%tm_map(removeWords, stopwords(kind="en")) %>% tm_map(stripWhitespace)
> dtm <- DocumentTermMatrix(corpus.clean)
> inspect(dtm[40:50, 10:15])
<<DocumentTermMatrix (documents: 11, terms: 6)>>
Non-/sparse entries: 0/66
Sparsity           : 100%
Maximal term length: 6
Weighting          : term frequency (tf)
Sample             :
    Terms
Docs “work” «mon aaaaa aaj aajtak aaya
  40      0    0     0   0      0    0
  41      0    0     0   0      0    0
  42      0    0     0   0      0    0
  43      0    0     0   0      0    0
  44      0    0     0   0      0    0
  45      0    0     0   0      0    0
  46      0    0     0   0      0    0
  47      0    0     0   0      0    0
  48      0    0     0   0      0    0
  49      0    0     0   0      0    0
  50      0    0     0   0      0    0
> View(Amazon_Shopping_Site_csv)
> df.train <- df[1:700,]
> df.test <- df[701:1022,]
> dtm.train <- dtm[1:700,]
> dtm.test <- dtm[701:1022,]
> corpus.clean.train <- corpus.clean[1:700]
> corpus.clean.test <- corpus.clean[701:1022]
>   dim(dtm.train)
[1]  700 4530
>   fivefreq <- findFreqTerms(dtm.train, 5)   
>   length((fivefreq))
[1] 296
>   dtm.train.nb <- DocumentTermMatrix(corpus.clean.train, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 296
>   dtm.test.nb <- DocumentTermMatrix(corpus.clean.test, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 296
>   convert_count <- function(x) {
+     y <- ifelse(x > 0, 1,0)
+     y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
+     y
+   }
>   trainNB <- apply(dtm.train.nb, 2, convert_count)
>   testNB <- apply(dtm.test.nb, 2, convert_count)  
>   system.time( classifier <- naiveBayes(trainNB, df.train$class,laplace = 1) )
Error in table(y, var) : all arguments must have the same length
Timing stopped at: 0.02 0.02 0.03
>   system.time( pred <- predict(classifier, newdata=testNB) )
Error in predict(classifier, newdata = testNB) : 
  object 'classifier' not found
Timing stopped at: 0 0 0
> df.train <- df[1:700,]
> df.test <- df[701:1000,]
> dtm.train <- dtm[1:700,]
> dtm.test <- dtm[701:1000,]
> corpus.clean.train <- corpus.clean[1:700]
> corpus.clean.test <- corpus.clean[701:1000]
> dim(dtm.train)
[1]  700 4530
> 
>   fivefreq <- findFreqTerms(dtm.train, 5)   
>   length((fivefreq))
[1] 296
>   
>   dtm.train.nb <- DocumentTermMatrix(corpus.clean.train, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 296
>   
>   dtm.test.nb <- DocumentTermMatrix(corpus.clean.test, control=list(dictionary = fivefreq))
>   dim(dtm.train.nb)
[1] 700 296
>   convert_count <- function(x) {
+     y <- ifelse(x > 0, 1,0)
+     y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
+     y
+   }
> trainNB <- apply(dtm.train.nb, 2, convert_count)
>   
>   testNB <- apply(dtm.test.nb, 2, convert_count)  
>   system.time( classifier <- naiveBayes(trainNB, df.train$class,laplace = 1) )
Error in table(y, var) : all arguments must have the same length
Timing stopped at: 0.01 0 0.01
> save.image("C:/Users/megha/OneDrive/Desktop/NIIT-21042019/Machine Learning/Project/Global.RData")
> View(Amazon_Shopping_Site_csv)
> View(Amazon_Shopping_Site_csv)
> View(Amazon_Shopping_Site_csv)
> View(df)
> 